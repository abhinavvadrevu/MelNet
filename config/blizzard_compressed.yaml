model:
  tier: 5
  layers: [5, 4, 3, 2, 2]
  hidden: 256
  gmm: 10
---
data:
  name: 'Blizzard'
  path: './datasets/segmented_compressed'
  extension: '*.wav'
---
audio:
  sr: 7000
  duration: 6.0
  n_mels: 180
  hop_length: 150
  win_length: 1080
  n_fft: 1080
  num_freq: 541
  ref_level_db: 20.0
  min_level_db: -80.0
---
train:
  num_workers: 4
  optimizer: 'adam'
  sgd:
    lr: 0.0001
    momentum: 0.9
  rmsprop: # from paper
    lr: 0.0001
    momentum: 0.9
  adam:
    lr: 0.0001
  # Gradient Accumulation
  # you'll be specifying batch size with argument of trainer.py
  # (update interval) * (batch size) = (paper's batch size) = 128
  update_interval: 128 # for batch size 1.
---
log:
  summary_interval: 1
  chkpt_dir: 'chkpt'
  log_dir: 'logs'
